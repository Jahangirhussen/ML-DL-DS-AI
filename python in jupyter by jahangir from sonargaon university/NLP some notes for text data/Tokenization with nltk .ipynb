{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47caf174-e466-4445-bed6-1e7c0749d0cb",
   "metadata": {},
   "source": [
    "# nltk for NPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27ec4c-58f9-4610-b83e-3899928fabcb",
   "metadata": {},
   "source": [
    "## nltk Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6ebe0d-4de3-4ff0-be5d-23b57f42a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f817c0c0-e056-4bd6-9db3-4acb1560b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\" A passionate researcher and programmer from Bangladesh. specializing in Machine Learning, Data Science, and competitive programming (LeetCode, Codeforces, CodeChef).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef0d850-55ab-43d4-8578-ad668536ca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A passionate researcher and programmer from Bangladesh. specializing in Machine Learning, Data Science, and competitive programming (LeetCode, Codeforces, CodeChef).\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a7ff4-b111-42dd-87e7-96b8ed476597",
   "metadata": {},
   "source": [
    "### Words tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7fe0f3-f3f7-4a29-a6d4-834da214ce22",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-weight:bold; font-family: monospace;\">word_tokenize(text)</span> — এই ফাংশনটি টেক্সটকে ছোট ছোট শব্দে (tokens) ভেঙে দেয়।  \n",
    "<span style=\"color:red; font-weight:bold; font-family: monospace;\">tokens</span> ভ্যারিয়েবলটিতে ঐ শব্দগুলোর তালিকা (list) সংরক্ষণ হয়।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03fac5cd-0267-4e47-8c56-1d8cbd50aaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'A',\n",
       " 'passionate',\n",
       " 'researcher',\n",
       " 'and',\n",
       " 'programmer',\n",
       " 'from',\n",
       " 'Bangladesh.',\n",
       " 'specializing',\n",
       " 'in',\n",
       " 'Machine',\n",
       " 'Learning,',\n",
       " 'Data',\n",
       " 'Science,',\n",
       " 'and',\n",
       " 'competitive',\n",
       " 'programming',\n",
       " '(LeetCode,',\n",
       " 'Codeforces,',\n",
       " 'CodeChef).']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_split = text.split(' ')\n",
    "text_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1a929c-805d-4234-9b88-ecf6db3b0f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee49052-aa9e-4756-bdab-d7fe2fa933c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'passionate', 'researcher', 'and', 'programmer', 'from', 'Bangladesh', '.', 'specializing', 'in', 'Machine', 'Learning', ',', 'Data', 'Science', ',', 'and', 'competitive', 'programming', '(', 'LeetCode', ',', 'Codeforces', ',', 'CodeChef', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ed9e8f-81bf-417e-b01e-64bc60dba022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6c25a-8110-4f66-bde5-2e08970a66e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69dd13-057f-4ec2-a63b-ec77396faff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a991ce-b16e-429d-a403-313eb615fd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cbc12d7-c3b0-4a21-bafc-c56f379b7479",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:red; font-weight:bold; font-family: monospace;\">sent_tokenize(text)</span> — এই ফাংশনটি টেক্সটকে ছোট ছোট বাক্যে (sentences) ভাগ করে।\n",
    "<span style=\"color:red; font-weight:bold; font-family: monospace;\">sentences</span> ভ্যারিয়েবলটিতে ঐ বাক্যগুলোর তালিকা (list) থাকে।"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c65bdd-8d90-4986-9fc3-982a179e4bda",
   "metadata": {},
   "source": [
    "### Sentance Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e162e5f6-fb0a-4246-b700-da304beb634c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jahangir Hussen  is a student of Computer Science and Engineering at Sonargaon University. He's passionate about many things: programming, Machine Learning, Data Science, and backend development. Every day, he sharpens his skills with platforms like LeetCode, Codeforces, and others — it's part of his growth mindset! Did you know he's also writing book chapters on topics like \"Data Privacy in AI\" and \"Nursing Leadership in Global Health\"? That’s impressive! Jahangir’s goal is clear: study in the U.S with a 100% scholarship. He’s not just skilled; he’s determined, hardworking, and focused. “Success,” he says, “is earned, not given.” Jahangir’s coding style speaks for itself — clean, efficient, and readable (which is rare among students). He’s fluent in English and Bangla; both languages help him communicate his ideas globally. So, what’s next for him? Stay tuned — the journey has just begun!\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Jahangir Hussen  is a student of Computer Science and Engineering at Sonargaon University. He's passionate about many things: programming, Machine Learning, Data Science, and backend development. Every day, he sharpens his skills with platforms like LeetCode, Codeforces, and others — it's part of his growth mindset! Did you know he's also writing book chapters on topics like \\\"Data Privacy in AI\\\" and \\\"Nursing Leadership in Global Health\\\"? That’s impressive! Jahangir’s goal is clear: study in the U.S with a 100% scholarship. He’s not just skilled; he’s determined, hardworking, and focused. “Success,” he says, “is earned, not given.” Jahangir’s coding style speaks for itself — clean, efficient, and readable (which is rare among students). He’s fluent in English and Bangla; both languages help him communicate his ideas globally. So, what’s next for him? Stay tuned — the journey has just begun!\"\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d13f760-e4f9-4ca0-a5f9-5203c6e91678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jahangir Hussen  is a student of Computer Science and Engineering at Sonargaon University.',\n",
       " \"He's passionate about many things: programming, Machine Learning, Data Science, and backend development.\",\n",
       " \"Every day, he sharpens his skills with platforms like LeetCode, Codeforces, and others — it's part of his growth mindset!\",\n",
       " 'Did you know he\\'s also writing book chapters on topics like \"Data Privacy in AI\" and \"Nursing Leadership in Global Health\"?',\n",
       " 'That’s impressive!',\n",
       " 'Jahangir’s goal is clear: study in the U.S with a 100% scholarship.',\n",
       " 'He’s not just skilled; he’s determined, hardworking, and focused.',\n",
       " '“Success,” he says, “is earned, not given.” Jahangir’s coding style speaks for itself — clean, efficient, and readable (which is rare among students).',\n",
       " 'He’s fluent in English and Bangla; both languages help him communicate his ideas globally.',\n",
       " 'So, what’s next for him?',\n",
       " 'Stay tuned — the journey has just begun!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50f122a-0771-4dd7-a7bb-1c57cac86f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.sent_tokenize(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57ee0d-1e3b-4e1b-878e-3d16282ced88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9806e-7a63-4318-b9e1-8c0ddf0f4231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45381a-2819-4c30-a86b-006f3bd8cd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e961418-48bb-4783-b553-5699da4b2cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a80bc8-045a-4bd8-bbfd-2396982e36e2",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-weight:bold; font-family: monospace;\">TreebankWordTokenizer()</span> — NLTK এর এই টোকেনাইজার দিয়ে <span style=\"color:red; font-weight:bold; font-family: monospace;\">text2</span> কে শব্দে ভাগ করা হয়। <span style=\"color:red; font-weight:bold; font-family: monospace;\">tokens</span> — ঐ ভাগ করা শব্দগুলো এখানে লিস্ট হিসেবে রাখা হয়। <span style=\"color:red; font-weight:bold; font-family: monospace;\">print(tokens)</span> — লিস্টটাকে কনসোলে দেখায়।\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c378dd-89c3-4b2d-90d9-a4bcc32ec232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jahangir', 'Hussen', 'is', 'a', 'student', 'of', 'Computer', 'Science', 'and', 'Engineering', 'at', 'Sonargaon', 'University.', 'He', \"'s\", 'passionate', 'about', 'many', 'things', ':', 'programming', ',', 'Machine', 'Learning', ',', 'Data', 'Science', ',', 'and', 'backend', 'development.', 'Every', 'day', ',', 'he', 'sharpens', 'his', 'skills', 'with', 'platforms', 'like', 'LeetCode', ',', 'Codeforces', ',', 'and', 'others', '—', 'it', \"'s\", 'part', 'of', 'his', 'growth', 'mindset', '!', 'Did', 'you', 'know', 'he', \"'s\", 'also', 'writing', 'book', 'chapters', 'on', 'topics', 'like', '``', 'Data', 'Privacy', 'in', 'AI', \"''\", 'and', '``', 'Nursing', 'Leadership', 'in', 'Global', 'Health', \"''\", '?', 'That’s', 'impressive', '!', 'Jahangir’s', 'goal', 'is', 'clear', ':', 'study', 'in', 'the', 'U.S', 'with', 'a', '100', '%', 'scholarship.', 'He’s', 'not', 'just', 'skilled', ';', 'he’s', 'determined', ',', 'hardworking', ',', 'and', 'focused.', '“Success', ',', '”', 'he', 'says', ',', '“is', 'earned', ',', 'not', 'given.”', 'Jahangir’s', 'coding', 'style', 'speaks', 'for', 'itself', '—', 'clean', ',', 'efficient', ',', 'and', 'readable', '(', 'which', 'is', 'rare', 'among', 'students', ')', '.', 'He’s', 'fluent', 'in', 'English', 'and', 'Bangla', ';', 'both', 'languages', 'help', 'him', 'communicate', 'his', 'ideas', 'globally.', 'So', ',', 'what’s', 'next', 'for', 'him', '?', 'Stay', 'tuned', '—', 'the', 'journey', 'has', 'just', 'begun', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(text2)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e7e41-4ca7-4ffe-a479-e2949632824a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ea755-8879-4b66-bff7-79ab95076f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae41bd5-263c-4c73-a812-bc57421b97c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40c89c47-54af-48bb-8712-d91704d13eef",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-weight:bold; font-family: monospace;\">RegexpTokenizer(r'\\w+')</span> — এই টোকেনাইজার শুধু অক্ষর ও সংখ্যার শব্দগুলো টোকেন হিসেবে নেবে। <span style=\"color:red; font-weight:bold; font-family: monospace;\">tokens</span> — <span style=\"color:red; font-weight:bold; font-family: monospace;\">text2</span> থেকে আলাদা করা শব্দগুলোর লিস্ট। <span style=\"color:red; font-weight:bold; font-family: monospace;\">print(tokens)</span> — ঐ টোকেনগুলো কনসোলে দেখায়।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f5ddd1-cc00-4feb-a9bc-2c0d7ef58dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jahangir', 'Hussen', 'is', 'a', 'student', 'of', 'Computer', 'Science', 'and', 'Engineering', 'at', 'Sonargaon', 'University', 'He', 's', 'passionate', 'about', 'many', 'things', 'programming', 'Machine', 'Learning', 'Data', 'Science', 'and', 'backend', 'development', 'Every', 'day', 'he', 'sharpens', 'his', 'skills', 'with', 'platforms', 'like', 'LeetCode', 'Codeforces', 'and', 'others', 'it', 's', 'part', 'of', 'his', 'growth', 'mindset', 'Did', 'you', 'know', 'he', 's', 'also', 'writing', 'book', 'chapters', 'on', 'topics', 'like', 'Data', 'Privacy', 'in', 'AI', 'and', 'Nursing', 'Leadership', 'in', 'Global', 'Health', 'That', 's', 'impressive', 'Jahangir', 's', 'goal', 'is', 'clear', 'study', 'in', 'the', 'U', 'S', 'with', 'a', '100', 'scholarship', 'He', 's', 'not', 'just', 'skilled', 'he', 's', 'determined', 'hardworking', 'and', 'focused', 'Success', 'he', 'says', 'is', 'earned', 'not', 'given', 'Jahangir', 's', 'coding', 'style', 'speaks', 'for', 'itself', 'clean', 'efficient', 'and', 'readable', 'which', 'is', 'rare', 'among', 'students', 'He', 's', 'fluent', 'in', 'English', 'and', 'Bangla', 'both', 'languages', 'help', 'him', 'communicate', 'his', 'ideas', 'globally', 'So', 'what', 's', 'next', 'for', 'him', 'Stay', 'tuned', 'the', 'journey', 'has', 'just', 'begun']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(text2)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d849a1-fb5a-4b7b-b782-d3baf1b3500e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733239e4-5363-48d4-8dfe-b57f02f9c962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "569e5f7e-34c0-4652-9b13-0e7cb52dbef4",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-weight:bold; font-family: monospace;\">WhitespaceTokenizer()</span> — স্পেস দিয়ে টেক্সট ভাগ করে শব্দগুলো আলাদা করে। <span style=\"color:red; font-weight:bold; font-family: monospace;\">tokens</span> — স্পেস দিয়ে আলাদা শব্দের লিস্ট। <span style=\"color:red; font-weight:bold; font-family: monospace;\">print(tokens)</span> — ঐ শব্দগুলো কনসোলে দেখায়।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7cd6da0-dd40-46ae-a628-e5d151f807c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jahangir', 'Hussen', 'is', 'a', 'student', 'of', 'Computer', 'Science', 'and', 'Engineering', 'at', 'Sonargaon', 'University.', \"He's\", 'passionate', 'about', 'many', 'things:', 'programming,', 'Machine', 'Learning,', 'Data', 'Science,', 'and', 'backend', 'development.', 'Every', 'day,', 'he', 'sharpens', 'his', 'skills', 'with', 'platforms', 'like', 'LeetCode,', 'Codeforces,', 'and', 'others', '—', \"it's\", 'part', 'of', 'his', 'growth', 'mindset!', 'Did', 'you', 'know', \"he's\", 'also', 'writing', 'book', 'chapters', 'on', 'topics', 'like', '\"Data', 'Privacy', 'in', 'AI\"', 'and', '\"Nursing', 'Leadership', 'in', 'Global', 'Health\"?', 'That’s', 'impressive!', 'Jahangir’s', 'goal', 'is', 'clear:', 'study', 'in', 'the', 'U.S', 'with', 'a', '100%', 'scholarship.', 'He’s', 'not', 'just', 'skilled;', 'he’s', 'determined,', 'hardworking,', 'and', 'focused.', '“Success,”', 'he', 'says,', '“is', 'earned,', 'not', 'given.”', 'Jahangir’s', 'coding', 'style', 'speaks', 'for', 'itself', '—', 'clean,', 'efficient,', 'and', 'readable', '(which', 'is', 'rare', 'among', 'students).', 'He’s', 'fluent', 'in', 'English', 'and', 'Bangla;', 'both', 'languages', 'help', 'him', 'communicate', 'his', 'ideas', 'globally.', 'So,', 'what’s', 'next', 'for', 'him?', 'Stay', 'tuned', '—', 'the', 'journey', 'has', 'just', 'begun!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "tokens = tokenizer.tokenize(text2)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54cd11-1201-492a-8334-b24d2d1e114f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f04ba8-2548-46e2-ae25-c6b1c41a4e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc1bf6-717d-4d99-8775-f2642b90bad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93f6f0ea-2c16-4a7c-923e-8d793aace5be",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-weight:bold; font-family: monospace;\">PunktSentenceTokenizer()</span> — এই টোকেনাইজার টেক্সটকে বাক্যে ভাগ করে। <span style=\"color:red; font-weight:bold; font-family: monospace;\">sentences</span> — বাক্যগুলোর লিস্ট। <span style=\"color:red; font-weight:bold; font-family: monospace;\">print(sentences)</span> — বাক্যগুলো কনসোলে দেখায়।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aea8a28-f0eb-466f-8859-160f1355905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jahangir Hussen  is a student of Computer Science and Engineering at Sonargaon University.', \"He's passionate about many things: programming, Machine Learning, Data Science, and backend development.\", \"Every day, he sharpens his skills with platforms like LeetCode, Codeforces, and others — it's part of his growth mindset!\", 'Did you know he\\'s also writing book chapters on topics like \"Data Privacy in AI\" and \"Nursing Leadership in Global Health\"?', 'That’s impressive!', 'Jahangir’s goal is clear: study in the U.S with a 100% scholarship.', 'He’s not just skilled; he’s determined, hardworking, and focused.', '“Success,” he says, “is earned, not given.” Jahangir’s coding style speaks for itself — clean, efficient, and readable (which is rare among students).', 'He’s fluent in English and Bangla; both languages help him communicate his ideas globally.', 'So, what’s next for him?', 'Stay tuned — the journey has just begun!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "sentences = tokenizer.tokenize(text2)\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919eceba-70e2-412e-a833-631f5a1c4c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1f828-6602-4acc-944f-cf02216ff2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e1e89-91e2-4f7c-9a05-de2770f72924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "009013cc-a1da-45b2-a21b-8457b9ce72aa",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-weight:bold; font-family: monospace;\">BlanklineTokenizer()</span> — এই টোকেনাইজার টেক্সটকে ফাঁকা লাইনের ভিত্তিতে ভাগ করে। <span style=\"color:red; font-weight:bold; font-family: monospace;\">paragraphs</span> — ফাঁকা লাইনে আলাদা করা প্যারাগ্রাফের লিস্ট। <span style=\"color:red; font-weight:bold; font-family: monospace;\">print(paragraphs)</span> — প্যারাগ্রাফগুলো কনসোলে দেখায়।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8494f87-929c-4dcf-aa59-c1526b20e7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jahangir Hussen  is a student of Computer Science and Engineering at Sonargaon University. He\\'s passionate about many things: programming, Machine Learning, Data Science, and backend development. Every day, he sharpens his skills with platforms like LeetCode, Codeforces, and others — it\\'s part of his growth mindset! Did you know he\\'s also writing book chapters on topics like \"Data Privacy in AI\" and \"Nursing Leadership in Global Health\"? That’s impressive! Jahangir’s goal is clear: study in the U.S with a 100% scholarship. He’s not just skilled; he’s determined, hardworking, and focused. “Success,” he says, “is earned, not given.” Jahangir’s coding style speaks for itself — clean, efficient, and readable (which is rare among students). He’s fluent in English and Bangla; both languages help him communicate his ideas globally. So, what’s next for him? Stay tuned — the journey has just begun!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import BlanklineTokenizer\n",
    "\n",
    "tokenizer = BlanklineTokenizer()\n",
    "paragraphs = tokenizer.tokenize(text2)\n",
    "print(paragraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345a6a2-1a3a-4000-8fb9-afb1fb954a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7d468-40c4-4aa7-a91d-afe5bc8d8485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0af5c3-d21c-4ef3-8d07-3fb0f98aa328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0cd6b2-9cf5-4cc9-9981-c5c4685f62d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9251817b-d44b-4e9c-af0c-926770077ca3",
   "metadata": {},
   "source": [
    "# Text Preprocessing in NLP  with Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9129e7-e620-4cd5-8e23-fef56f2b1ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ece7910-6509-4fe7-a299-854c9a5eabf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@User when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @User when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                Bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Twitter Sentiments.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a640501c-78e2-4ee5-bc14-120a8b31752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['id', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20674b27-cb91-4f5c-b95b-af51cf931f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@User when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0   @User when a father is dysfunctional and is s...\n",
       "1  @user @user thanks for #lyft credit i can't us...\n",
       "2                                Bihday your majesty\n",
       "3  #model   i love u take with u all the time in ...\n",
       "4             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac3787-ce6b-4c73-bbdf-1784937aeecf",
   "metadata": {},
   "source": [
    "## Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94a1d4e3-b66b-49f1-a949-9364cac3f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean tweet']=df['tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ec07d82-9aa7-421b-9bc8-3194f17189fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@User when a father is dysfunctional and is s...</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0   @User when a father is dysfunctional and is s...   \n",
       "1  @user @user thanks for #lyft credit i can't us...   \n",
       "2                                Bihday your majesty   \n",
       "3  #model   i love u take with u all the time in ...   \n",
       "4             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean tweet  \n",
       "0   @user when a father is dysfunctional and is s...  \n",
       "1  @user @user thanks for #lyft credit i can't us...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1069f5b7-3778-41f5-8aac-a916fb3d4877",
   "metadata": {},
   "source": [
    "## Removal of Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ee763dc-dcf9-45eb-aab9-0998fda977b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4eb4dc0b-1e48-486d-89c8-470f0f5601a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations_JK(text):\n",
    "    punctuations = string.punctuation\n",
    "    return text.translate(str.maketrans('', '', punctuations))\n",
    "\n",
    "\n",
    "df['clean tweet'] = df['clean tweet'].apply(lambda x: remove_punctuations_JK(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaa57c03-7f4d-4d5d-a953-d4de70acbdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@User when a father is dysfunctional and is s...</td>\n",
       "      <td>user when a father is dysfunctional and is so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0   @User when a father is dysfunctional and is s...   \n",
       "1  @user @user thanks for #lyft credit i can't us...   \n",
       "2                                Bihday your majesty   \n",
       "3  #model   i love u take with u all the time in ...   \n",
       "4             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean tweet  \n",
       "0   user when a father is dysfunctional and is so...  \n",
       "1  user user thanks for lyft credit i cant use ca...  \n",
       "2                                bihday your majesty  \n",
       "3  model   i love u take with u all the time in u...  \n",
       "4               factsguide society now    motivation  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b41b3-cad6-42af-bdc3-87c741573e6d",
   "metadata": {},
   "source": [
    "## Removal of Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d9527df-4997-4ab4-a0cc-732e22194abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a , about , above , after , again , against , ain , all , am , an , and , any , are , aren , aren't , as , at , be , because , been , before , being , below , between , both , but , by , can , couldn , couldn't , d , did , didn , didn't , do , does , doesn , doesn't , doing , don , don't , down , during , each , few , for , from , further , had , hadn , hadn't , has , hasn , hasn't , have , haven , haven't , having , he , he'd , he'll , her , here , hers , herself , he's , him , himself , his , how , i , i'd , if , i'll , i'm , in , into , is , isn , isn't , it , it'd , it'll , it's , its , itself , i've , just , ll , m , ma , me , mightn , mightn't , more , most , mustn , mustn't , my , myself , needn , needn't , no , nor , not , now , o , of , off , on , once , only , or , other , our , ours , ourselves , out , over , own , re , s , same , shan , shan't , she , she'd , she'll , she's , should , shouldn , shouldn't , should've , so , some , such , t , than , that , that'll , the , their , theirs , them , themselves , then , there , these , they , they'd , they'll , they're , they've , this , those , through , to , too , under , until , up , ve , very , was , wasn , wasn't , we , we'd , we'll , we're , were , weren , weren't , we've , what , when , where , which , while , who , whom , why , will , with , won , won't , wouldn , wouldn't , y , you , you'd , you'll , your , you're , yours , yourself , yourselves , you've\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_jk=\" , \".join(stopwords.words('english'))\n",
    "stop_jk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb2f7207-152e-4c87-b8a7-a751333da12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1441"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_jk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38fe3b06-095d-47a1-85ac-060e751b92d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
    "\n",
    "\n",
    "df['clean tweet'] = df['clean tweet'].apply(lambda x: remove_stopwords(x))\n",
    "len(STOPWORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d9d9e68-50cc-4003-b3dd-dca897f86cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@User when a father is dysfunctional and is s...</td>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>user user thanks lyft credit cant use cause do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love u take u time urð± ðððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0   @User when a father is dysfunctional and is s...   \n",
       "1  @user @user thanks for #lyft credit i can't us...   \n",
       "2                                Bihday your majesty   \n",
       "3  #model   i love u take with u all the time in ...   \n",
       "4             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean tweet  \n",
       "0  user father dysfunctional selfish drags kids d...  \n",
       "1  user user thanks lyft credit cant use cause do...  \n",
       "2                                     bihday majesty  \n",
       "3  model love u take u time urð± ðððð...  \n",
       "4                      factsguide society motivation  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31905985-4ea4-40a0-8716-4b62f8fcd2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
